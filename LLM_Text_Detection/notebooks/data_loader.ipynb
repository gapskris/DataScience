{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Text Classification - Data Loader for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the unwanted warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required modules \n",
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car car around sinc becam famou henri ford cre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transport larg necess countri worldwid doubt c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>america love affair vehicl seem cool say elisa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>often ride car drive one motor vehicl work sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>car wonder thing perhap one world greatest adv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  car car around sinc becam famou henri ford cre...          0\n",
       "1  transport larg necess countri worldwid doubt c...          0\n",
       "2  america love affair vehicl seem cool say elisa...          0\n",
       "3  often ride car drive one motor vehicl work sto...          0\n",
       "4  car wonder thing perhap one world greatest adv...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset from csv file \n",
    "df = pd.read_csv('../data/filtered_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automobil use averag use transport ever sinc r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>univers educ prepar student employ also teach ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purpos univers educ often debat believ prepar ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>believ univers educ multipl function import ed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could imagin would like limit usag car could s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>univers educ mani purpos two main one prepar s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>believ univers educ provid student skill knowl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fellow citizen mani reason limit car usag outs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agre univers educ function function includ dev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>varieti opinion univers educ peopl think prepa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  automobil use averag use transport ever sinc r...          0\n",
       "1  univers educ prepar student employ also teach ...          1\n",
       "2  purpos univers educ often debat believ prepar ...          1\n",
       "3  believ univers educ multipl function import ed...          1\n",
       "4  could imagin would like limit usag car could s...          0\n",
       "5  univers educ mani purpos two main one prepar s...          1\n",
       "6  believ univers educ provid student skill knowl...          1\n",
       "7  fellow citizen mani reason limit car usag outs...          0\n",
       "8  agre univers educ function function includ dev...          1\n",
       "9  varieti opinion univers educ peopl think prepa...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts and labels\n",
    "X = list(df['text'])\n",
    "y = list(df['generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets object\n",
    "\n",
    "# create data dictionary\n",
    "train_data_dict = {\n",
    "    'text': X_train,\n",
    "    'generated': y_train,\n",
    "}\n",
    "validation_data_dict = {\n",
    "    'text': X_valid,\n",
    "    'generated': y_valid,\n",
    "}\n",
    "\n",
    "# create data object for both train split and validation split\n",
    "train_dataset = datasets.Dataset.from_dict(train_data_dict)\n",
    "validation_dataset = datasets.Dataset.from_dict(validation_data_dict)\n",
    "\n",
    "# wraps up both the data objects into DatasetDict object\n",
    "data = datasets.DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 4.68kB/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 95.1kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 480kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 693kB/s]\n",
      "Map: 100%|██████████| 4332/4332 [00:03<00:00, 1173.27 examples/s]\n",
      "Map: 100%|██████████| 1084/1084 [00:00<00:00, 1259.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# convert the texts into tokens using transformers AutoTokenizer\n",
    "\n",
    "# model name or checkpoint name\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "# initialize tokenizer object\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "# function which convert text into tokens \n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "# apply tokenizer on all texts\n",
    "tokenized_datasets = data.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted columns from tokenized dataset\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# rename the \"generated\" to \"labels\"\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"generated\", \"labels\")\n",
    "\n",
    "# Set the format of the datasets so they return PyTorch tensors instead of lists\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloaders for further process\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([8]),\n",
       " 'input_ids': torch.Size([8, 512]),\n",
       " 'token_type_ids': torch.Size([8, 512]),\n",
       " 'attention_mask': torch.Size([8, 512])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
